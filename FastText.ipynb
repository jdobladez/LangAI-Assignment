{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tokenized_non-eng.csv\",\n",
    "                 na_values=['[deleted]', '[removed]']).dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Converting to FastText Format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0    auhtor_ID   \n0               0    t2_10uons  \\\n1               1    t2_10uons   \n2               2    t2_10uons   \n3               3    t2_10uons   \n4               4    t2_10uons   \n...           ...          ...   \n76400       82611  t2_57ogt82f   \n76401       82612  t2_57ogt82f   \n76402       82613  t2_57ogt82f   \n76403       82614  t2_57ogt82f   \n76404       82615  t2_57ogt82f   \n\n                                                    post     nationality   \n0      isn't, show. legally binding. depends also ran...         Finland  \\\n1      game game played. game played calculated compa...         Finland   \n2      logic usa shitty place live (with ~1 shooting ...         Finland   \n3      referring add lot ea, activision etc.. re-rele...         Finland   \n4      get another role support lel people thinking 2...         Finland   \n...                                                  ...             ...   \n76400  sergeant york. wwi lend it'self films. fought ...  United Kingdom   \n76401  position person get short term fame committing...  United Kingdom   \n76402  read label. high red meat, yet others low. qua...  United Kingdom   \n76403  traitors. suggesting treason. treason death pe...  United Kingdom   \n76404  drug trade staffed benefit claimants. that's b...  United Kingdom   \n\n         Poles                                        post_tokens  \n0      Western  ['is', \"n't\", ',', 'show', '.', 'legally', 'bi...  \n1      Western  ['game', 'game', 'played', '.', 'game', 'playe...  \n2      Western  ['logic', 'usa', 'shitty', 'place', 'live', '(...  \n3      Western  ['referring', 'add', 'lot', 'ea', ',', 'activi...  \n4      Western  ['get', 'another', 'role', 'support', 'lel', '...  \n...        ...                                                ...  \n76400  Western  ['sergeant', 'york', '.', 'wwi', 'lend', \"it's...  \n76401  Western  ['position', 'person', 'get', 'short', 'term',...  \n76402  Western  ['read', 'label', '.', 'high', 'red', 'meat', ...  \n76403  Western  ['traitors', '.', 'suggesting', 'treason', '.'...  \n76404  Western  ['drug', 'trade', 'staffed', 'benefit', 'claim...  \n\n[76405 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>auhtor_ID</th>\n      <th>post</th>\n      <th>nationality</th>\n      <th>Poles</th>\n      <th>post_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>t2_10uons</td>\n      <td>isn't, show. legally binding. depends also ran...</td>\n      <td>Finland</td>\n      <td>Western</td>\n      <td>['is', \"n't\", ',', 'show', '.', 'legally', 'bi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>t2_10uons</td>\n      <td>game game played. game played calculated compa...</td>\n      <td>Finland</td>\n      <td>Western</td>\n      <td>['game', 'game', 'played', '.', 'game', 'playe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>t2_10uons</td>\n      <td>logic usa shitty place live (with ~1 shooting ...</td>\n      <td>Finland</td>\n      <td>Western</td>\n      <td>['logic', 'usa', 'shitty', 'place', 'live', '(...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>t2_10uons</td>\n      <td>referring add lot ea, activision etc.. re-rele...</td>\n      <td>Finland</td>\n      <td>Western</td>\n      <td>['referring', 'add', 'lot', 'ea', ',', 'activi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>t2_10uons</td>\n      <td>get another role support lel people thinking 2...</td>\n      <td>Finland</td>\n      <td>Western</td>\n      <td>['get', 'another', 'role', 'support', 'lel', '...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>76400</th>\n      <td>82611</td>\n      <td>t2_57ogt82f</td>\n      <td>sergeant york. wwi lend it'self films. fought ...</td>\n      <td>United Kingdom</td>\n      <td>Western</td>\n      <td>['sergeant', 'york', '.', 'wwi', 'lend', \"it's...</td>\n    </tr>\n    <tr>\n      <th>76401</th>\n      <td>82612</td>\n      <td>t2_57ogt82f</td>\n      <td>position person get short term fame committing...</td>\n      <td>United Kingdom</td>\n      <td>Western</td>\n      <td>['position', 'person', 'get', 'short', 'term',...</td>\n    </tr>\n    <tr>\n      <th>76402</th>\n      <td>82613</td>\n      <td>t2_57ogt82f</td>\n      <td>read label. high red meat, yet others low. qua...</td>\n      <td>United Kingdom</td>\n      <td>Western</td>\n      <td>['read', 'label', '.', 'high', 'red', 'meat', ...</td>\n    </tr>\n    <tr>\n      <th>76403</th>\n      <td>82614</td>\n      <td>t2_57ogt82f</td>\n      <td>traitors. suggesting treason. treason death pe...</td>\n      <td>United Kingdom</td>\n      <td>Western</td>\n      <td>['traitors', '.', 'suggesting', 'treason', '.'...</td>\n    </tr>\n    <tr>\n      <th>76404</th>\n      <td>82615</td>\n      <td>t2_57ogt82f</td>\n      <td>drug trade staffed benefit claimants. that's b...</td>\n      <td>United Kingdom</td>\n      <td>Western</td>\n      <td>['drug', 'trade', 'staffed', 'benefit', 'claim...</td>\n    </tr>\n  </tbody>\n</table>\n<p>76405 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Creating a copy as data\n",
    "data = df.copy()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to flatten the list of tokens into a single string\n",
    "def flatten_tokens(tokens):\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Add the __label__ prefix to each label\n",
    "train_data['category'] = train_data['Poles'].apply(lambda x: f'__label__{x}')\n",
    "test_data['category'] = test_data['Poles'].apply(lambda x: f'__label__{x}')\n",
    "\n",
    "# Saving the CSV file as a text file to train/test the classifier\n",
    "train_data[['category', 'post']].to_csv('train.txt',\n",
    "                                          index = False,\n",
    "                                          sep = ' ',\n",
    "                                          header = None,\n",
    "                                          quoting = csv.QUOTE_NONE,\n",
    "                                          quotechar = \"\",\n",
    "                                          escapechar = \" \")\n",
    "\n",
    "test_data[['category', 'post']].to_csv('test.txt',\n",
    "                                     index = False,\n",
    "                                     sep = ' ',\n",
    "                                     header = None,\n",
    "                                     quoting = csv.QUOTE_NONE,\n",
    "                                     quotechar = \"\",\n",
    "                                     escapechar = \" \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(15281, 0.9464040311497939, 0.9464040311497939)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the fastText classifier\n",
    "model = fasttext.train_supervised('train.txt', wordNgrams = 2)\n",
    "\n",
    "# Evaluating performance on the entire test file\n",
    "model.test('test.txt', k=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 15281 is the number of data points in the test set\n",
    "* 0.946469 is both the precision and the recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Meaning of k parameter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Taken from Chat)\n",
    "Now, when you set k=1, it means you are only considering the top-1 prediction for each example. In your case, the precision and recall at 1 are both approximately 0.9465.\n",
    "\n",
    "When you set k=2, it means you are considering the top-2 predictions for each example. This changes the evaluation metric because now the model is allowed to provide two predictions per example, and correctness is assessed based on whether the correct category is among the top-2 predictions.\n",
    "\n",
    "So it does not make sense to set k to anything above 1 in case of binary predictions since there are only two categories."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9464040311497939\n",
      "Precision: 0.9469357542616063\n",
      "Recall: 0.9464040311497939\n",
      "F1 Score: 0.9441547757598423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     12174\n",
      "           1       0.96      0.77      0.85      3107\n",
      "\n",
      "    accuracy                           0.95     15281\n",
      "   macro avg       0.95      0.88      0.91     15281\n",
      "weighted avg       0.95      0.95      0.94     15281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Load the test data\n",
    "with open('test.txt', 'r', encoding='utf-8') as f:\n",
    "    test_lines = f.readlines()\n",
    "\n",
    "# Extract labels and texts from the test data\n",
    "test_labels = [line.split()[0] for line in test_lines]\n",
    "test_texts = [' '.join(line.split()[1:]) for line in test_lines]\n",
    "\n",
    "# Get predictions from the model\n",
    "predictions = [model.predict(text)[0][0].replace('__label__', '') for text in test_texts]\n",
    "\n",
    "# Create label mapping to map strings as integers (0 or 1)\n",
    "label_mapping = {'__label__Western': 0, '__label__Eastern': 1}\n",
    "label_mapping_pred = {'Western': 0, 'Eastern': 1}\n",
    "\n",
    "# Convert labels to integers using the mapping\n",
    "test_labels = [label_mapping[label] for label in test_labels]\n",
    "predictions = [label_mapping_pred[pred] for pred in predictions]\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions, average='weighted')\n",
    "recall = recall_score(test_labels, predictions, average='weighted')\n",
    "f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "classification_rep = classification_report(test_labels, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print('Classification Report:\\n', classification_rep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}